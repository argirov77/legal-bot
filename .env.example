CHROMA_PERSIST_DIR=/chroma_db
VECTOR_STORE=mock
EMBEDDING_MODEL_PATH=/models/all-MiniLM-L6-v2
EMBEDDING_DEVICE=cpu

# LLM configuration
LLM_PROVIDER=transformers
LLM_MODEL_PATH=/models/bgpt-7b
# Допълнителни ключове за обратна съвместимост (ползва се първият наличен):
# LLM_BG1_PATH=/models/bgpt-7b
# LLM_BG2_PATH=/models/gemma-2-bg
LLM_DEVICE=auto
LLM_DEVICE_MAP=single
LLM_TORCH_DTYPE=float16
LLM_QUANT=
LLM_MAX_TOKENS=256
LLM_TEMPERATURE=0.0
LLM_STUB=false

OCR_LANG=bul
INSTALL_HEAVY=true
# USE_CUDA=true ще накара Dockerfile да инсталира CUDA вариант на PyTorch
USE_CUDA=false
FORCE_LOAD_ON_START=false
